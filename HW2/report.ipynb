{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sklearn의 Scaler를 이용하거나 누락 값을 제거하는 등의 방식으로 preprocess하려했으나, \n",
    "sklearn 관련 import가 자꾸 되지 않아서 작성한 코드를 실행해보지 못했습니다.\n",
    "따라서 코드를 실행했을 때 결과를 확인하지 못하였고, anneal.py를 제대로 수정하지 못했습니다.\n",
    "수업에서 학습한 내용과 이전에 수강한 과목의 과제를 참조해 글로만 보고서 작성하는 점 양해 부탁드립니다.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "결정 트리는 데이터의 규칙을 트리 형태로 분할해 가는 모델이다. 하지만 트리 깊이를 제한하지 않으면 오버피팅이 될 수 있다.\n",
    "따라서 머신러닝 모델을 설계할 때 필요한 것이 Hyperparameter이다. 이를 적절히 변경하며 test set의 accuracy를 개선하고자 했다.\n",
    "\n",
    "min_samples_split는 중간 노드의 분할을 위한 최소 샘플 데이터 수이다. 과적합을 제어하고, 작을수록 과적합 가능성이 증가한다.\n",
    "min_sample_leaf는 리프 노드가 되고 위한 최소 샘플 데이터 수이다. 과적합을 제어하고, 작을수록 좋다.\n",
    "max_depth는 최대 깊이이다. 기본값 None은 완전 분할될 때까지 분할하거나 리프노드 최소 샘플까지 분할한다.\n",
    "max_features는 최적 분할을 위해 다룰 최대 피터 개수이다. 기본값 None은 모든 피처를 고려한다.\n",
    "\n",
    "DecisionTree의 깊이를 제한하지 않으면 트리가 무한정 깊어질 수 있다.\n",
    "따라서 Pruning하지 않은 트리는 오버피팅이 될 수 있고 일반화되지 않는다.\n",
    "\n",
    "먼저 min_sample_leaf로 리프 노드가 되는 하한 데이터 개수를 높이면 오버피팅이 개선된다.\n",
    "min_sample_leaf = None일 때, train set에서는 100% 정확하나, test set에서는 15%정도 떨어지는 정확도를 보였다.\n",
    "min_sample_leaf = 6일 때, train set의 정확도는 떨어졌으나, test set의 정확도는 5%정도 증가했다.\n",
    "\n",
    "추가로 max_depth = n 으로 하면 연속 질문을 최대 n개로 제한된다. None으로 설정할 때보다 오버피팅이 줄어든다.\n",
    "이는 훈련 세트의 정확도는 떨어뜨리지만, 테스트 세트의 성능은 개선시킨다.\n",
    "\n",
    "min_samples_split의 경우, 작은 값으로 설정할수록 오버피팅 가능성이 증가했다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4d2538657c01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_module\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAnnealDataModule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\82105\\Downloads\\HW2\\model\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdecision_tree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'DecisionTree'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\82105\\Downloads\\HW2\\model\\decision_tree.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from model import DecisionTree\n",
    "from data_module import AnnealDataModule\n",
    "from sklearn.metrics import accuracy_score as acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataModule = AnnealDataModule('data/anneal_train.csv', 'data/anneal_test.csv')\n",
    "data = DataModule.get_dataset()\n",
    "\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree()\n",
    "model.load_model('temp.pickle')\n",
    "preds = model.predict(X_test)\n",
    "print(\"Accuracy = %.2f%%\" % (acc(y_test, preds) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed4b82d56d1a788c3484ff7d149de62ebbfea2ad1c17c7e940b351523245b447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
